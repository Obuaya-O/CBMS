{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Out-Cross-Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOCV is a type of k-fold cross-validation where k is equal to the number of samples. For each iteration, a single sample is used as the test set, the remaining n -1 samples make-up the training set to build the predictive model estimate model performance (Kuo et al., 2020).\n",
    "\n",
    "Classifiers: Based on the non-linearity and imbalanced nature of primary endpoint types used  in clinical trial protocols, we decided to evaluate four machine learning algorithms: Complement Na√Øve Bayes (CNB) (Rennie et al., 2003), Multi-layer Perceptron (MLP) (Kruse et al., 2022), Random Forest (RF) (Ho, 1995) and Support Vector Machine (SVM) (Hearst et al., 1998). \n",
    "\n",
    "Word embedding techniques: Term-Frequency Inverse Document Frequency (TF-IDF) (Bafna et al., 2016), global vectors for word representations (GloVe) (Pennington et al., 2014) and SciBERT (Beltagy et al., 2019).\n",
    "\n",
    "Parameter tuning: We used the scikit-learn tool GridSearchCV in Python (scikit-learn, version 1.6.1) to perform a comprehensive search over specified parameter values for each classifier, with the aim to assess potential predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of LOOCV\n",
    "1. Reduced bias: By validating on each observation only once, LOOCV produces an almost unbiased assessment of model performance.\n",
    "2. Maximised training data: Every data point is included in the training set for all but one fold, enabling nearly the whole dataset informs model fitting in each iteration.\n",
    "3. Enhanced robustness: LOOCV is particularly suited to small datasets like the EUCT-NS dataset. LOOCV avoids overlly small training sets that can arise with other cross-validation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages and Libraries\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Import chosen model(s)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euct_df = pd.read_csv(euct_df) \n",
    "# Data already preprocessed since prior clustering task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euct_df['concat_corpus'] = euct_df['Title']+ \" \" + euct_df['Objective'] + \" \" + euct_df['pr_endpoint'] + \" \" + euct_df['endpoint_description']\n",
    "euct_df.head()\n",
    "\n",
    "# Fill NaN values with an empty string\n",
    "euct_df['concat_corpus'] = euct_df['concat_corpus'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the embeddings for the corpus\n",
    "For TF-IDF: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "For GloVe: https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/DOCUMENT_POOL_EMBEDDINGS.md\n",
    "For SciBERT: https://github.com/allenai/scibert?tab=readme-ov-file\n",
    "\n",
    "These are the word embeddings I used but there are other options to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X = data.data # feature matrix after embedding transformation\n",
    "y = euct_df['manual_label'].values # target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search:\n",
    "An exhaustive search strategy that evaluates every possible combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "mdl = Model(random_state=42) # Replace Model with your chosen model, e.g., RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the hyperparameters and their values for grid search. I looked at the scikit-learn documentation for my chosen models\n",
    "# to find the appropriate parameters.\n",
    "parameters = {'parameters of the model'} \n",
    "\n",
    "mdl = Model()\n",
    "pipeline = make_pipeline(mdl)\n",
    "mdl = GridSearchCV(pipeline, parameters, cv=10, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "mdl.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", mdl.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise LOOCV and the best performing model\n",
    "# We perform Leave-One-Out Cross-Validation (LOOCV) to evaluate the best parameters of each model\n",
    "loo = LeaveOneOut()\n",
    "mdl = MDL(#parameters of mdl, change these to the best parameters found by GridSearchCV)\n",
    "predictions = []\n",
    "actuals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Leave-One-Out Cross-Validation\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    mdl.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = mdl.predict(X_test)\n",
    "\n",
    "    predictions.append(y_pred[0])\n",
    "    actuals.append(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "classification_metrics = classification_report(actuals, predictions, output_dict=True)\n",
    "confusion_mat = confusion_matrix(actuals, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=mdl.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering_endpoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
